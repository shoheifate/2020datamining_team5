{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "from matplotlib import pylab as plt\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dict = {\"Normal\":0, \"Fire\":1, \"Water\":2, \"Electric\":3, \"Grass\":4, \"Ice\":5,\n",
    "    \"Fighting\":6, \"Poison\":7, \"Ground\":8, \"Flying\":9, \"Psychic\":10, \"Bug\":11,\n",
    "    \"Rock\":12, \"Ghost\":13, \"Dragon\":14, \"Dark\":15, \"Steel\":16,\"Fairy\":17 }\n",
    "def read_types(path):\n",
    "    \"\"\"タイプデータを読み込んで返す.\n",
    "\n",
    "    渡されたパスからデータを読み込み，タイプデータのみを抽出，整形し返す.\n",
    "\n",
    "    Args:\n",
    "        path (str) : データパス\n",
    "\n",
    "    Returns:\n",
    "         Numpy arrays. タイプデータリストを二つ\n",
    "\n",
    "    \"\"\"\n",
    "    print(f'\\rloading types data ... ', end='')\n",
    "    df = pd.read_csv(path+'Pokemon.csv', sep=',')\n",
    "    df.drop_duplicates(subset='Number', inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    ind = df[df['Type2'].isnull()]['Type2'].index\n",
    "    df.iloc[ind, 3] = df.iloc[ind, 2]\n",
    "\n",
    "    df_1 = df[\"Type1\"][:801]\n",
    "    df_1 = df_1.map(type_dict)\n",
    "    type1 = df_1.values\n",
    "\n",
    "    df_2 = df[\"Type2\"][:801]\n",
    "    df_2 = df_2.map(type_dict)\n",
    "    type2 = df_2.values\n",
    "\n",
    "    print(f'\\rloading types data ... done')\n",
    "    return type1, type2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type1,type2 = read_types('data/')\n",
    "# print(type1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, metrics, preprocessing, model_selection #機械学習用のライブラリを利用\n",
    "from mlxtend.plotting import plot_decision_regions #学習結果をプロットする外部ライブラリを利用\n",
    "import codecs\n",
    "import dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "with codecs.open('data/convert_data//No_Mega_Weight_new.csv', 'r', 'utf-8', 'ignore') as f:\n",
    "    df_pokemon_all = pd.read_csv(f)\n",
    "df_pokemon_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Type1 = df_pokemon_all.iloc[:,2]\n",
    "#Type_change = np.array(list(weight))\n",
    "\n",
    "#change_li = Type_change.reshape(-1,1)\n",
    "Type2 = df_pokemon_all.iloc[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset_image\n",
    "X = dataset_image.Data_set()\n",
    "X1 = np.array(list(X))\n",
    "X1 = X1.reshape(X1.shape[0], -1)\n",
    "df = pd.DataFrame(X1)\n",
    "df_change = pd.concat([df_pokemon_all, df],axis=1)\n",
    "df_change\n",
    "weight = df_change.iloc[:,13:27]\n",
    "train_data = weight.values.tolist()\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import dataset_image\n",
    "\n",
    "#print(X1)\n",
    "train_X1 = train_data\n",
    "train_y1 = Type1\n",
    "(train_X1, test_X1 ,train_y1, test_y1) = train_test_split(train_X1, train_y1, test_size = 0.2, random_state = 666)\n",
    "#print(train_X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = RandomForestClassifier(\n",
    "    bootstrap=True, #ランダムにデータを使う。falseだと順番ずつデータを取る。日付とかを重要視するらしい。\n",
    "    class_weight=None, #不均衡を考慮しないならNone,考慮するならclass_weight='balanced'\n",
    "    criterion='gini', #スプリットの品質を測定する機能。\n",
    "    max_depth=15, #最大の深さ\n",
    "    max_features=10, \n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=3,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=300,\n",
    "    n_jobs=1,\n",
    "    oob_score=False,\n",
    "    random_state=2525,\n",
    "    verbose=0,\n",
    "    warm_start=False)\n",
    "\n",
    "clf1 = clf1.fit(train_X1, train_y1)\n",
    "pred1 = clf1.predict(test_X1)\n",
    "print(f\"acc: {clf1.score(test_X1, test_y1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for predx,test_y in zip(pred1,test_y1):\n",
    "    \n",
    "    print(f\"pred : {predx}------\",f\"test : {test_y}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#説明変数XとタイプのみのY分離\n",
    "import pandas as pd\n",
    "poke = pd.read_csv('data/convert_data/No_Mega_Weight_new.csv')\n",
    "poke_noType = poke.drop(['Number','Type1','Type2','Total','HP','Attack','Defense','SpecialAtk','SpecialDef','Speed','Generation','Legendary'],axis=1)\n",
    "X = []\n",
    "Y = []\n",
    "Y_type2 = []\n",
    "l = len(poke)\n",
    "col = poke_noType.columns.values\n",
    "coll = len(col)\n",
    "index = 0\n",
    "while index < l:\n",
    "    column = 0\n",
    "    Xdata = []\n",
    "    Y_nt = []\n",
    "    while column < coll: \n",
    "        Xdata.append(poke_noType.iat[index,column])\n",
    "        column += 1\n",
    "\n",
    "    Y_nt.append(poke.at[index,'Type1'])\n",
    "    if type(poke.at[index,'Type2']) is not type(poke.at[index,'Type1']):\n",
    "        Y_nt.append(poke.at[index,'Type1'])\n",
    "    else:\n",
    "        Y_nt.append(poke.at[index,'Type2'])\n",
    "    X.append(Xdata)\n",
    "    Y.append(Y_nt)\n",
    "    index += 1\n",
    "\n",
    "for i in range(l):\n",
    "    Y_type2.append(Y[i][1])\n",
    "\n",
    "    \n",
    "print(Y_type2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X2 = train_data\n",
    "train_y2 = Y_type2\n",
    "(train_X2, test_X2 ,train_y2, test_y2) = train_test_split(train_X2, train_y2, test_size = 0.2, random_state = 666)\n",
    "#print(train_X1)\n",
    "clf2 = RandomForestClassifier(\n",
    "    bootstrap=True, #ランダムにデータを使う。falseだと順番ずつデータを取る。日付とかを重要視するらしい。\n",
    "    class_weight=None, #不均衡を考慮しないならNone,考慮するならclass_weight='balanced'\n",
    "    criterion='gini', #スプリットの品質を測定する機能。\n",
    "    max_depth=15, #最大の深さ\n",
    "    max_features=10, \n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=3,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=300,\n",
    "    n_jobs=1,\n",
    "    oob_score=False,\n",
    "    random_state=2525,\n",
    "    verbose=0,\n",
    "    warm_start=False)\n",
    "\n",
    "clf2 = clf2.fit(train_X2, train_y2)\n",
    "pred2 = clf2.predict(test_X2)\n",
    "print(f\"acc: {clf2.score(test_X2, test_y2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(test_y1))\n",
    "pred1_2 = clf1.predict(test_X2)\n",
    "pred2_1 = clf2.predict(test_X1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(pred1_2))\n",
    "# print(len(test_y2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0\n",
    "for pred_1,testy1,pred_2,testy2,pred_12,pred_21 in zip(pred1,test_y1,pred2,test_y2,pred1_2,pred2_1):\n",
    "    if pred_1 == testy1:\n",
    "        j+=1\n",
    "    elif pred_2 == testy2:\n",
    "        j+=1\n",
    "    elif pred_12 == testy2:\n",
    "        j+=1\n",
    "    elif pred_21 == testy1:\n",
    "        j+=1\n",
    "\n",
    "print(j)\n",
    "score = j / 177\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#グリッドサーチ込み\n",
    "search_params = {\n",
    "     'n_estimators'      : [5, 10, 20, 30, 50, 100, 300],\n",
    "      'max_features'      : [3, 5, 10, 15, 20],\n",
    "      'random_state'      : [2525],\n",
    "      'n_jobs'            : [1],\n",
    "      'min_samples_split' : [3, 5, 10, 15, 20, 25, 30, 40, 50, 100],\n",
    "      'max_depth'         : [3, 5, 10, 15, 20, 25, 30, 40, 50, 100]\n",
    "}\n",
    "\n",
    "gs1 = GridSearchCV(RandomForestClassifier(),           # 対象の機械学習モデル\n",
    "                  search_params,   # 探索パラメタ辞書\n",
    "                  cv=5,            # クロスバリデーションの分割数\n",
    "                  verbose=True,    # ログ表示\n",
    "                  n_jobs=-1)       # 並列処理\n",
    "gs1 = gs1.fit(train_X1, train_y1)\n",
    "#gs2 = gs1.fit(train_X2, train_y2)\n",
    "pred_gs1 = gs1.predict(test_X1)\n",
    "#pred_gs2 = gs2.predict(test_X2)\n",
    "print(f\"acc: {gs1.score(test_X1, test_y1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs2 = gs1.fit(train_X2, train_y2)\n",
    "pred_gs2 = gs2.predict(test_X2)\n",
    "print(f\"acc: {gs2.score(test_X2, test_y2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gs1_2 = gs1.predict(test_X2)\n",
    "pred_gs2_1 = gs2.predict(test_X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "js=0\n",
    "for pred_1,testy1,pred_2,testy2,pred_12,pred_21 in zip(pred_gs1,test_y1,pred_gs2,test_y2,pred_gs1_2,pred_gs2_1):\n",
    "    if pred_1 == testy1:\n",
    "        js+=1\n",
    "    elif pred_2 == testy2:\n",
    "        js+=1\n",
    "    elif pred_12 == testy2:\n",
    "        js+=1\n",
    "    elif pred_21 == testy1:\n",
    "        js+=1\n",
    "\n",
    "print(js)\n",
    "score = js / 177\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Xgen1 = train_data[:801]\n",
    "train_ygen1 = Type1[:801]\n",
    "train_ygen2 = Y_type2[:801]\n",
    "#a_train, a_test = train_test_split(a, shuffle=False)\n",
    "#(train_X2, test_X2 ,train_y2, test_y2) = train_test_split(, train_y2, test_size = 0.3, random_state = 666)\n",
    "#print(train_X1)\n",
    "\n",
    "test_Xgen1 = train_data[802:882]\n",
    "test_ygen1 = Type1[802:882]\n",
    "test_ygen2 = Y_type2[802:882]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_Xgen1)\n",
    "print(train_ygen2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_params = {\n",
    "#     'max_depth'         : [3, 5, 10, 15, 20, 25, 30, 40, 50, 100],\n",
    "#     'max_features'      : [3, 5, 10, 15, 20],\n",
    "#      'n_estimators'      : [5, 10, 20, 30, 50, 100, 300],\n",
    "#       'random_state'      : [2525],\n",
    "#       'n_jobs'            : [1],\n",
    "#       'min_samples_split' : [3, 5, 10, 15, 20, 25, 30, 40, 50, 100],\n",
    "#     'min_impurity_decrease':[0.0]\n",
    "# }\n",
    "# gs1 = GridSearchCV(RandomForestClassifier(),\n",
    "#                   search_params,\n",
    "#                   cv=3,            # クロスバリデーションの分割数\n",
    "#                   verbose=True,    # ログ表示\n",
    "#                   n_jobs=-1)       # 並列処理\n",
    "\n",
    "clf_gs1 = RandomForestClassifier(\n",
    "    bootstrap=True, #ランダムにデータを使う。falseだと順番ずつデータを取る。日付とかを重要視するらしい。\n",
    "    class_weight=None, #不均衡を考慮しないならNone,考慮するならclass_weight='balanced'\n",
    "    criterion='gini', #スプリットの品質を測定する機能。\n",
    "    max_depth=15, #最大の深さ\n",
    "    max_features=10, \n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=3,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=300,\n",
    "    n_jobs=1,\n",
    "    oob_score=False,\n",
    "    random_state=2525,\n",
    "    verbose=0,\n",
    "    warm_start=False)\n",
    "\n",
    "clf_gs1 = clf_gs1.fit(train_Xgen1, train_ygen1)\n",
    "pred_gs1 = clf_gs1.predict(test_Xgen1)\n",
    "print(f\"acc: {clf_gs1.score(test_Xgen1, test_ygen1)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(len(test_ygen1))\n",
    "print(len(pred_gs1))\n",
    "cm = confusion_matrix(test_ygen1, pred_gs1)\n",
    "print(cm)\n",
    "sns.heatmap(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_gs2 = RandomForestClassifier(\n",
    "    bootstrap=True, #ランダムにデータを使う。falseだと順番ずつデータを取る。日付とかを重要視するらしい。\n",
    "    class_weight=None, #不均衡を考慮しないならNone,考慮するならclass_weight='balanced'\n",
    "    criterion='gini', #スプリットの品質を測定する機能。\n",
    "    max_depth=15, #最大の深さ\n",
    "    max_features=10, \n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=3,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=300,\n",
    "    n_jobs=1,\n",
    "    oob_score=False,\n",
    "    random_state=2525,\n",
    "    verbose=0,\n",
    "    warm_start=False)\n",
    "\n",
    "clf_gs2 = clf_gs2.fit(train_Xgen1, train_ygen2)\n",
    "pred_gs2 = clf_gs2.predict(test_Xgen1)\n",
    "print(f\"acc: {clf_gs2.score(test_Xgen1, test_ygen2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycm import ConfusionMatrix\n",
    "print(len(test_ygen2))\n",
    "print(len(pred_gs2))\n",
    "cm = confusion_matrix(test_ygen1, pred_gs1)\n",
    "print(cm)\n",
    "sns.heatmap(cm)\n",
    "# print(cm1)\n",
    "# sns.heatmap(cm1)\n",
    "\n",
    "mapping = {\"Normal\":0, \"Fire\":1, \"Water\":2, \"Electric\":3, \"Grass\":4, \"Ice\":5,\n",
    "    \"Fighting\":6, \"Poison\":7, \"Ground\":8, \"Flying\":9, \"Psychic\":10, \"Bug\":11,\n",
    "    \"Rock\":12, \"Ghost\":13, \"Dragon\":14, \"Dark\":15, \"Steel\":16,\"Fairy\":17 }\n",
    "\n",
    "\n",
    "# gs2 = GridSearchCV(RandomForestClassifier(),\n",
    "#                   search_params,\n",
    "#                   cv=3,            # クロスバリデーションの分割数\n",
    "#                   verbose=True,    # ログ表示\n",
    "#                   n_jobs=-1) \n",
    "# gs2 = gs2.fit(train_Xgen1,train_ygen2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pred_gs2))\n",
    "print(len(pred_gs1))\n",
    "pred_gs1 = clf_gs1.predict(test_Xgen1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(gs1.score(test_Xgen1,test_ygen1))\n",
    "# print(gs2.score(test_Xgen1,test_ygen2))\n",
    "\n",
    "#print(f\"acc: {gs2.score(train_Xgen2_test, train_ygen2_test2)}\")\n",
    "jj = 0\n",
    "for gs1,test1,gs2,test2 in zip(pred_gs1 ,test_ygen1,pred_gs2,test_ygen2):\n",
    "    if gs1 == test1:\n",
    "        jj+=1\n",
    "    elif gs2 == test2:\n",
    "        jj+=1\n",
    "    elif gs2 == test1:\n",
    "        jj+=1\n",
    "    elif gs1 == test2:\n",
    "        jj+=1\n",
    "print(jj)\n",
    "score = jj / 80\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_gs = GridSearchCV(RandomForestClassifier(),           # 対象の機械学習モデル\n",
    "                  search_params,   # 探索パラメタ辞書\n",
    "                  cv=5,            # クロスバリデーションの分割数\n",
    "                  verbose=True,    # ログ表示\n",
    "                  n_jobs=-1)       # 並列処理\n",
    "gs_gs1 = gs_gs.fit(train_Xgen1, train_ygen1)\n",
    "pred_gs_gs1 = gs_gs1.predict(test_Xgen1)\n",
    "print(f\"acc: {gs_gs1.score(test_Xgen1, test_ygen1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_gs2 = gs_gs.fit(train_Xgen1, train_ygen2)\n",
    "pred_gs_gs2 = gs_gs2.predict(test_Xgen1)\n",
    "print(f\"acc: {gs_gs1.score(test_Xgen1, test_ygen2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jjs = 0\n",
    "for gs1,test1,gs2,test2 in zip(pred_gs_gs1 ,test_ygen1,pred_gs_gs2,test_ygen2):\n",
    "    if gs1 == test1:\n",
    "        jjs+=1\n",
    "    elif gs2 == test2:\n",
    "        jjs+=1\n",
    "    elif gs2 == test1:\n",
    "        jjs+=1\n",
    "    elif gs1 == test2:\n",
    "        jjs+=1\n",
    "print(jjs)\n",
    "score = jjs / 80\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(gs1.best_estimator_)\n",
    "#print(gs2.best_estimator_)\n",
    "print(gs_gs1.best_estimator_)\n",
    "print(gs_gs2.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
